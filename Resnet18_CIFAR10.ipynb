{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9v01wL7bhs"
      },
      "source": [
        "###1. Use Resnet18 to train on CIFAR-10\t\n",
        "\n",
        "###2. Experiment on the following and compare the result with baseline\n",
        "* Input image normalization\n",
        "* Data augmentation\n",
        "* Different base learning rate and update strategy\n",
        "* Different batch size\n",
        "\n",
        "###3. Print test loss and test acc\n",
        "\n",
        "###4. Plot train-loss, val-loss, train-acc, val-acc\n",
        "\n",
        "###5. Accuracy(>90%拿滿，>80%才有基本分)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uTY8C-LBhDTX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from matplotlib.colors import Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "io7k6zHGb1OJ"
      },
      "outputs": [],
      "source": [
        "# Create SummaryWriter\n",
        "writer = SummaryWriter(\"../tensorboard\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqc_D_uEhc1O",
        "outputId": "921d269d-f865-4ae2-a73d-11977f6f9d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# 檢查是否可用gpu\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CrsS13SChs9b"
      },
      "outputs": [],
      "source": [
        "# setting parameter\n",
        "EPOCH = 320     \n",
        "BATCH_SIZE = 128    \n",
        "lr = 0.1        \n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "e0dddca853b346029d59165177eb7a7f",
            "7ba6819814e141eb8334c854c2fbddd0",
            "eae82692647a460bb72cdc819db30e48",
            "43b4f6866bb04b4b861e1f7d8770c921",
            "e2f941f618d7456899f7aa914a51a367",
            "cb647ed2322441e6b5ed076023a79347",
            "3ce7c157195c4406b23ea5443e966130",
            "47051a50b5e94bc4be684908e9de6e8f",
            "5dcee7bc4b0245e19cc7b3b9922d7523",
            "ef5c4d4ee24b4afb96da843e5326b695",
            "7cd57a831e9c4ae586263b21a9942a61"
          ]
        },
        "id": "3LzusjVfhxJ3",
        "outputId": "11bb3aff-98ab-404f-92c0-4f5c1626d76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0dddca853b346029d59165177eb7a7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "[0.49022064 0.48086175 0.4456753 ] [0.24722584 0.24344158 0.26102957]\n"
          ]
        }
      ],
      "source": [
        "# 計算normalization需要的mean & std\n",
        "def get_mean_std(dataset, ratio=0.3):\n",
        "    # Get mean and std by sample ratio\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=int(len(dataset)*ratio), shuffle=True, num_workers=2)\n",
        "\n",
        "    data = iter(dataloader).next()[0]     # get the first iteration data\n",
        "    mean = np.mean(data.numpy(), axis=(0,2,3))\n",
        "    std = np.std(data.numpy(), axis=(0,2,3))\n",
        "    return mean, std\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_mean, train_std = get_mean_std(train_dataset)\n",
        "\n",
        "print(train_mean, train_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LkcHJBCRpiwq"
      },
      "outputs": [],
      "source": [
        "# 計算Gaussian noise\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5NGnL4rP6ofO"
      },
      "outputs": [],
      "source": [
        "# data augmentation & normalization\n",
        "transform_train = transforms.Compose([\n",
        "    # data augmentation\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # transforms.Resize(224),\n",
        "    # transforms.RandomCrop(192),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(0.2),\n",
        "    # transforms.ColorJitter(brightness=0.5),\n",
        "    # transforms.ColorJitter(contrast=0.5),\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # data normalization    # standardization: (image - train_mean) / train_std\n",
        "    # transforms.Lambda(lambda t: t.expand(3, -1, -1)),\n",
        "    # transforms.Normalize((0.5,) * 3, (0.5,) * 3)\n",
        "    transforms.Normalize(train_mean, train_std)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # data normalization    # standardization: (image - train_mean) / train_std\n",
        "    #transforms.Lambda(lambda t: t.expand(3, -1, -1)),\n",
        "    #transforms.Normalize((0.5,) * 3, (0.5,) * 3)  \n",
        "    transforms.Normalize(train_mean, train_std)  \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaJyYUXj6rNW",
        "outputId": "aab33f6c-272c-4eb1-be65-f3451687a67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train length:  45000\n",
            "val length:  5000\n",
            "test length:  10000\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_ds = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# 檢查training dataset長怎麼樣 \n",
        "#print(trainset)\n",
        "#print(\"trainset length: \", len(trainset))\n",
        "#print(\"classes: \", trainset.classes)\n",
        "\n",
        "# Cifar-10的標籤: ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# split validation dataset\n",
        "torch.manual_seed(43)     # 確保每次獲得相同的驗證集\n",
        "val_size = 5000       # 取5000張驗證集(0.1 of trainset)\n",
        "train_size = len(trainset) - val_size\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "print(\"train length: \", len(train_ds))\n",
        "print(\"val length: \", len(val_ds))\n",
        "print(\"test length: \", len(test_ds))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   #生成batch \n",
        "valloader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EgJejgUOVviV"
      },
      "outputs": [],
      "source": [
        "# learning rate shedule\n",
        "def adjust_learning_rate(optim, epoch, lr):\n",
        "    # define your lr scheduler\n",
        "    lr = lr * (0.1 ** (epoch //30 ) )\n",
        "    for param_group in optim.param_groups:    # change the lr to what you define\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfBB9RKK6t8e",
        "outputId": "014fe063-0549-479c-a9d0-b1575c2dd865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1\n",
            "learning rate:  0.1\n",
            "Train loss: 2.146 | Train acc: 0.310\n",
            "Val loss: 1.653 | Val acc: 0.396\n",
            "\n",
            "Epoch: 2\n",
            "learning rate:  0.1\n",
            "Train loss: 1.507 | Train acc: 0.449\n",
            "Val loss: 1.447 | Val acc: 0.476\n",
            "\n",
            "Epoch: 3\n",
            "learning rate:  0.1\n",
            "Train loss: 1.322 | Train acc: 0.526\n",
            "Val loss: 1.285 | Val acc: 0.545\n",
            "\n",
            "Epoch: 4\n",
            "learning rate:  0.1\n",
            "Train loss: 1.191 | Train acc: 0.577\n",
            "Val loss: 1.364 | Val acc: 0.531\n",
            "\n",
            "Epoch: 5\n",
            "learning rate:  0.1\n",
            "Train loss: 1.105 | Train acc: 0.611\n",
            "Val loss: 1.284 | Val acc: 0.574\n",
            "\n",
            "Epoch: 6\n",
            "learning rate:  0.1\n",
            "Train loss: 1.028 | Train acc: 0.640\n",
            "Val loss: 1.125 | Val acc: 0.616\n",
            "\n",
            "Epoch: 7\n",
            "learning rate:  0.1\n",
            "Train loss: 0.985 | Train acc: 0.657\n",
            "Val loss: 1.267 | Val acc: 0.588\n",
            "\n",
            "Epoch: 8\n",
            "learning rate:  0.1\n",
            "Train loss: 0.937 | Train acc: 0.674\n",
            "Val loss: 1.097 | Val acc: 0.615\n",
            "\n",
            "Epoch: 9\n",
            "learning rate:  0.1\n",
            "Train loss: 0.900 | Train acc: 0.688\n",
            "Val loss: 1.006 | Val acc: 0.652\n",
            "\n",
            "Epoch: 10\n",
            "learning rate:  0.1\n",
            "Train loss: 0.874 | Train acc: 0.698\n",
            "Val loss: 1.018 | Val acc: 0.650\n",
            "\n",
            "Epoch: 11\n",
            "learning rate:  0.1\n",
            "Train loss: 0.847 | Train acc: 0.706\n",
            "Val loss: 0.980 | Val acc: 0.665\n",
            "\n",
            "Epoch: 12\n",
            "learning rate:  0.1\n",
            "Train loss: 0.830 | Train acc: 0.713\n",
            "Val loss: 0.894 | Val acc: 0.694\n",
            "\n",
            "Epoch: 13\n",
            "learning rate:  0.1\n",
            "Train loss: 0.812 | Train acc: 0.722\n",
            "Val loss: 0.948 | Val acc: 0.677\n",
            "\n",
            "Epoch: 14\n",
            "learning rate:  0.1\n",
            "Train loss: 0.803 | Train acc: 0.721\n",
            "Val loss: 0.896 | Val acc: 0.684\n",
            "\n",
            "Epoch: 15\n",
            "learning rate:  0.1\n",
            "Train loss: 0.791 | Train acc: 0.730\n",
            "Val loss: 0.909 | Val acc: 0.692\n",
            "\n",
            "Epoch: 16\n",
            "learning rate:  0.1\n",
            "Train loss: 0.785 | Train acc: 0.730\n",
            "Val loss: 0.823 | Val acc: 0.714\n",
            "\n",
            "Epoch: 17\n",
            "learning rate:  0.1\n",
            "Train loss: 0.763 | Train acc: 0.740\n",
            "Val loss: 0.836 | Val acc: 0.711\n",
            "\n",
            "Epoch: 18\n",
            "learning rate:  0.1\n",
            "Train loss: 0.756 | Train acc: 0.742\n",
            "Val loss: 0.920 | Val acc: 0.693\n",
            "\n",
            "Epoch: 19\n",
            "learning rate:  0.1\n",
            "Train loss: 0.761 | Train acc: 0.740\n",
            "Val loss: 0.972 | Val acc: 0.680\n",
            "\n",
            "Epoch: 20\n",
            "learning rate:  0.1\n",
            "Train loss: 0.740 | Train acc: 0.747\n",
            "Val loss: 0.878 | Val acc: 0.704\n",
            "\n",
            "Epoch: 21\n",
            "learning rate:  0.1\n",
            "Train loss: 0.740 | Train acc: 0.746\n",
            "Val loss: 0.846 | Val acc: 0.710\n",
            "\n",
            "Epoch: 22\n",
            "learning rate:  0.1\n",
            "Train loss: 0.732 | Train acc: 0.749\n",
            "Val loss: 0.855 | Val acc: 0.709\n",
            "\n",
            "Epoch: 23\n",
            "learning rate:  0.1\n",
            "Train loss: 0.732 | Train acc: 0.749\n",
            "Val loss: 0.995 | Val acc: 0.671\n",
            "\n",
            "Epoch: 24\n",
            "learning rate:  0.1\n",
            "Train loss: 0.728 | Train acc: 0.750\n",
            "Val loss: 0.811 | Val acc: 0.720\n",
            "\n",
            "Epoch: 25\n",
            "learning rate:  0.1\n",
            "Train loss: 0.716 | Train acc: 0.755\n",
            "Val loss: 0.923 | Val acc: 0.691\n",
            "\n",
            "Epoch: 26\n",
            "learning rate:  0.1\n",
            "Train loss: 0.714 | Train acc: 0.756\n",
            "Val loss: 0.819 | Val acc: 0.718\n",
            "\n",
            "Epoch: 27\n",
            "learning rate:  0.1\n",
            "Train loss: 0.708 | Train acc: 0.759\n",
            "Val loss: 0.818 | Val acc: 0.730\n",
            "\n",
            "Epoch: 28\n",
            "learning rate:  0.1\n",
            "Train loss: 0.711 | Train acc: 0.757\n",
            "Val loss: 0.859 | Val acc: 0.710\n",
            "\n",
            "Epoch: 29\n",
            "learning rate:  0.1\n",
            "Train loss: 0.704 | Train acc: 0.760\n",
            "Val loss: 0.831 | Val acc: 0.721\n",
            "\n",
            "Epoch: 30\n",
            "learning rate:  0.1\n",
            "Train loss: 0.692 | Train acc: 0.764\n",
            "Val loss: 0.926 | Val acc: 0.682\n",
            "\n",
            "Epoch: 31\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.697 | Train acc: 0.761\n",
            "Val loss: 0.841 | Val acc: 0.715\n",
            "\n",
            "Epoch: 32\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.503 | Train acc: 0.826\n",
            "Val loss: 0.534 | Val acc: 0.821\n",
            "\n",
            "Epoch: 33\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.441 | Train acc: 0.848\n",
            "Val loss: 0.511 | Val acc: 0.823\n",
            "\n",
            "Epoch: 34\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.414 | Train acc: 0.858\n",
            "Val loss: 0.523 | Val acc: 0.820\n",
            "\n",
            "Epoch: 35\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.398 | Train acc: 0.864\n",
            "Val loss: 0.502 | Val acc: 0.830\n",
            "\n",
            "Epoch: 36\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.380 | Train acc: 0.869\n",
            "Val loss: 0.488 | Val acc: 0.832\n",
            "\n",
            "Epoch: 37\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.370 | Train acc: 0.874\n",
            "Val loss: 0.496 | Val acc: 0.828\n",
            "\n",
            "Epoch: 38\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.363 | Train acc: 0.876\n",
            "Val loss: 0.483 | Val acc: 0.834\n",
            "\n",
            "Epoch: 39\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.349 | Train acc: 0.880\n",
            "Val loss: 0.477 | Val acc: 0.838\n",
            "\n",
            "Epoch: 40\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.346 | Train acc: 0.882\n",
            "Val loss: 0.502 | Val acc: 0.830\n",
            "\n",
            "Epoch: 41\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.337 | Train acc: 0.883\n",
            "Val loss: 0.488 | Val acc: 0.831\n",
            "\n",
            "Epoch: 42\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.331 | Train acc: 0.885\n",
            "Val loss: 0.471 | Val acc: 0.838\n",
            "\n",
            "Epoch: 43\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.323 | Train acc: 0.889\n",
            "Val loss: 0.492 | Val acc: 0.839\n",
            "\n",
            "Epoch: 44\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.322 | Train acc: 0.888\n",
            "Val loss: 0.475 | Val acc: 0.840\n",
            "\n",
            "Epoch: 45\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.309 | Train acc: 0.893\n",
            "Val loss: 0.467 | Val acc: 0.843\n",
            "\n",
            "Epoch: 46\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.309 | Train acc: 0.893\n",
            "Val loss: 0.476 | Val acc: 0.836\n",
            "\n",
            "Epoch: 47\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.304 | Train acc: 0.894\n",
            "Val loss: 0.498 | Val acc: 0.833\n",
            "\n",
            "Epoch: 48\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.301 | Train acc: 0.895\n",
            "Val loss: 0.487 | Val acc: 0.837\n",
            "\n",
            "Epoch: 49\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.297 | Train acc: 0.897\n",
            "Val loss: 0.489 | Val acc: 0.841\n",
            "\n",
            "Epoch: 50\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.291 | Train acc: 0.898\n",
            "Val loss: 0.483 | Val acc: 0.840\n",
            "\n",
            "Epoch: 51\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.294 | Train acc: 0.896\n",
            "Val loss: 0.490 | Val acc: 0.835\n",
            "\n",
            "Epoch: 52\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.285 | Train acc: 0.899\n",
            "Val loss: 0.488 | Val acc: 0.834\n",
            "\n",
            "Epoch: 53\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.289 | Train acc: 0.899\n",
            "Val loss: 0.518 | Val acc: 0.830\n",
            "\n",
            "Epoch: 54\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.279 | Train acc: 0.902\n",
            "Val loss: 0.536 | Val acc: 0.823\n",
            "\n",
            "Epoch: 55\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.284 | Train acc: 0.901\n",
            "Val loss: 0.516 | Val acc: 0.828\n",
            "\n",
            "Epoch: 56\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.280 | Train acc: 0.902\n",
            "Val loss: 0.514 | Val acc: 0.828\n",
            "\n",
            "Epoch: 57\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.275 | Train acc: 0.904\n",
            "Val loss: 0.517 | Val acc: 0.832\n",
            "\n",
            "Epoch: 58\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.274 | Train acc: 0.903\n",
            "Val loss: 0.559 | Val acc: 0.822\n",
            "\n",
            "Epoch: 59\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.278 | Train acc: 0.902\n",
            "Val loss: 0.519 | Val acc: 0.826\n",
            "\n",
            "Epoch: 60\n",
            "learning rate:  0.010000000000000002\n",
            "Train loss: 0.268 | Train acc: 0.907\n",
            "Val loss: 0.516 | Val acc: 0.838\n",
            "\n",
            "Epoch: 61\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.275 | Train acc: 0.904\n",
            "Val loss: 0.524 | Val acc: 0.832\n",
            "\n",
            "Epoch: 62\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.208 | Train acc: 0.929\n",
            "Val loss: 0.464 | Val acc: 0.847\n",
            "\n",
            "Epoch: 63\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.186 | Train acc: 0.936\n",
            "Val loss: 0.475 | Val acc: 0.846\n",
            "\n",
            "Epoch: 64\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.174 | Train acc: 0.941\n",
            "Val loss: 0.448 | Val acc: 0.848\n",
            "\n",
            "Epoch: 65\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.166 | Train acc: 0.944\n",
            "Val loss: 0.454 | Val acc: 0.854\n",
            "\n",
            "Epoch: 66\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.162 | Train acc: 0.944\n",
            "Val loss: 0.461 | Val acc: 0.854\n",
            "\n",
            "Epoch: 67\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.160 | Train acc: 0.945\n",
            "Val loss: 0.453 | Val acc: 0.860\n",
            "\n",
            "Epoch: 68\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.151 | Train acc: 0.950\n",
            "Val loss: 0.460 | Val acc: 0.852\n",
            "\n",
            "Epoch: 69\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.147 | Train acc: 0.951\n",
            "Val loss: 0.469 | Val acc: 0.857\n",
            "\n",
            "Epoch: 70\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.146 | Train acc: 0.950\n",
            "Val loss: 0.463 | Val acc: 0.854\n",
            "\n",
            "Epoch: 71\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.144 | Train acc: 0.951\n",
            "Val loss: 0.453 | Val acc: 0.855\n",
            "\n",
            "Epoch: 72\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.138 | Train acc: 0.952\n",
            "Val loss: 0.455 | Val acc: 0.854\n",
            "\n",
            "Epoch: 73\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.140 | Train acc: 0.953\n",
            "Val loss: 0.472 | Val acc: 0.854\n",
            "\n",
            "Epoch: 74\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.133 | Train acc: 0.954\n",
            "Val loss: 0.473 | Val acc: 0.855\n",
            "\n",
            "Epoch: 75\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.130 | Train acc: 0.957\n",
            "Val loss: 0.485 | Val acc: 0.849\n",
            "\n",
            "Epoch: 76\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.129 | Train acc: 0.956\n",
            "Val loss: 0.472 | Val acc: 0.856\n",
            "\n",
            "Epoch: 77\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.125 | Train acc: 0.957\n",
            "Val loss: 0.490 | Val acc: 0.856\n",
            "\n",
            "Epoch: 78\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.123 | Train acc: 0.959\n",
            "Val loss: 0.470 | Val acc: 0.856\n",
            "\n",
            "Epoch: 79\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.122 | Train acc: 0.958\n",
            "Val loss: 0.494 | Val acc: 0.855\n",
            "\n",
            "Epoch: 80\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.119 | Train acc: 0.960\n",
            "Val loss: 0.472 | Val acc: 0.856\n",
            "\n",
            "Epoch: 81\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.119 | Train acc: 0.959\n",
            "Val loss: 0.483 | Val acc: 0.856\n",
            "\n",
            "Epoch: 82\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.115 | Train acc: 0.960\n",
            "Val loss: 0.492 | Val acc: 0.856\n",
            "\n",
            "Epoch: 83\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.114 | Train acc: 0.961\n",
            "Val loss: 0.498 | Val acc: 0.854\n",
            "\n",
            "Epoch: 84\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.114 | Train acc: 0.962\n",
            "Val loss: 0.486 | Val acc: 0.857\n",
            "\n",
            "Epoch: 85\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.111 | Train acc: 0.963\n",
            "Val loss: 0.499 | Val acc: 0.856\n",
            "\n",
            "Epoch: 86\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.109 | Train acc: 0.963\n",
            "Val loss: 0.503 | Val acc: 0.846\n",
            "\n",
            "Epoch: 87\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.106 | Train acc: 0.964\n",
            "Val loss: 0.520 | Val acc: 0.854\n",
            "\n",
            "Epoch: 88\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.108 | Train acc: 0.964\n",
            "Val loss: 0.484 | Val acc: 0.854\n",
            "\n",
            "Epoch: 89\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.103 | Train acc: 0.964\n",
            "Val loss: 0.495 | Val acc: 0.855\n",
            "\n",
            "Epoch: 90\n",
            "learning rate:  0.0010000000000000002\n",
            "Train loss: 0.103 | Train acc: 0.963\n",
            "Val loss: 0.510 | Val acc: 0.856\n",
            "\n",
            "Epoch: 91\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.104 | Train acc: 0.965\n",
            "Val loss: 0.493 | Val acc: 0.863\n",
            "\n",
            "Epoch: 92\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.095 | Train acc: 0.968\n",
            "Val loss: 0.505 | Val acc: 0.857\n",
            "\n",
            "Epoch: 93\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.095 | Train acc: 0.968\n",
            "Val loss: 0.526 | Val acc: 0.857\n",
            "\n",
            "Epoch: 94\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.093 | Train acc: 0.969\n",
            "Val loss: 0.504 | Val acc: 0.855\n",
            "\n",
            "Epoch: 95\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.089 | Train acc: 0.970\n",
            "Val loss: 0.479 | Val acc: 0.864\n",
            "\n",
            "Epoch: 96\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.094 | Train acc: 0.968\n",
            "Val loss: 0.502 | Val acc: 0.859\n",
            "\n",
            "Epoch: 97\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.091 | Train acc: 0.970\n",
            "Val loss: 0.508 | Val acc: 0.857\n",
            "\n",
            "Epoch: 98\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.088 | Train acc: 0.971\n",
            "Val loss: 0.501 | Val acc: 0.857\n",
            "\n",
            "Epoch: 99\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.088 | Train acc: 0.970\n",
            "Val loss: 0.499 | Val acc: 0.852\n",
            "\n",
            "Epoch: 100\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.090 | Train acc: 0.970\n",
            "Val loss: 0.478 | Val acc: 0.861\n",
            "\n",
            "Epoch: 101\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.091 | Train acc: 0.970\n",
            "Val loss: 0.490 | Val acc: 0.855\n",
            "\n",
            "Epoch: 102\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.087 | Train acc: 0.970\n",
            "Val loss: 0.490 | Val acc: 0.860\n",
            "\n",
            "Epoch: 103\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.086 | Train acc: 0.971\n",
            "Val loss: 0.488 | Val acc: 0.864\n",
            "\n",
            "Epoch: 104\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.089 | Train acc: 0.969\n",
            "Val loss: 0.504 | Val acc: 0.853\n",
            "\n",
            "Epoch: 105\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.086 | Train acc: 0.970\n",
            "Val loss: 0.526 | Val acc: 0.850\n",
            "\n",
            "Epoch: 106\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.086 | Train acc: 0.970\n",
            "Val loss: 0.497 | Val acc: 0.857\n",
            "\n",
            "Epoch: 107\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.089 | Train acc: 0.970\n",
            "Val loss: 0.520 | Val acc: 0.852\n",
            "\n",
            "Epoch: 108\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.493 | Val acc: 0.860\n",
            "\n",
            "Epoch: 109\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.086 | Train acc: 0.971\n",
            "Val loss: 0.496 | Val acc: 0.857\n",
            "\n",
            "Epoch: 110\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.505 | Val acc: 0.855\n",
            "\n",
            "Epoch: 111\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.086 | Train acc: 0.972\n",
            "Val loss: 0.500 | Val acc: 0.857\n",
            "\n",
            "Epoch: 112\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.495 | Val acc: 0.861\n",
            "\n",
            "Epoch: 113\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.086 | Train acc: 0.971\n",
            "Val loss: 0.511 | Val acc: 0.857\n",
            "\n",
            "Epoch: 114\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.085 | Train acc: 0.972\n",
            "Val loss: 0.511 | Val acc: 0.858\n",
            "\n",
            "Epoch: 115\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.515 | Val acc: 0.851\n",
            "\n",
            "Epoch: 116\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.083 | Train acc: 0.973\n",
            "Val loss: 0.504 | Val acc: 0.857\n",
            "\n",
            "Epoch: 117\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.083 | Train acc: 0.973\n",
            "Val loss: 0.511 | Val acc: 0.856\n",
            "\n",
            "Epoch: 118\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.085 | Train acc: 0.972\n",
            "Val loss: 0.498 | Val acc: 0.856\n",
            "\n",
            "Epoch: 119\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.516 | Val acc: 0.859\n",
            "\n",
            "Epoch: 120\n",
            "learning rate:  0.00010000000000000003\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.518 | Val acc: 0.853\n",
            "\n",
            "Epoch: 121\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.519 | Val acc: 0.854\n",
            "\n",
            "Epoch: 122\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.519 | Val acc: 0.859\n",
            "\n",
            "Epoch: 123\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.529 | Val acc: 0.856\n",
            "\n",
            "Epoch: 124\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.520 | Val acc: 0.855\n",
            "\n",
            "Epoch: 125\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.512 | Val acc: 0.859\n",
            "\n",
            "Epoch: 126\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.085 | Train acc: 0.972\n",
            "Val loss: 0.512 | Val acc: 0.855\n",
            "\n",
            "Epoch: 127\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.531 | Val acc: 0.848\n",
            "\n",
            "Epoch: 128\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.506 | Val acc: 0.856\n",
            "\n",
            "Epoch: 129\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.529 | Val acc: 0.851\n",
            "\n",
            "Epoch: 130\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.519 | Val acc: 0.855\n",
            "\n",
            "Epoch: 131\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.505 | Val acc: 0.857\n",
            "\n",
            "Epoch: 132\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.085 | Train acc: 0.972\n",
            "Val loss: 0.503 | Val acc: 0.853\n",
            "\n",
            "Epoch: 133\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.513 | Val acc: 0.855\n",
            "\n",
            "Epoch: 134\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.500 | Val acc: 0.856\n",
            "\n",
            "Epoch: 135\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.519 | Val acc: 0.856\n",
            "\n",
            "Epoch: 136\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.081 | Train acc: 0.974\n",
            "Val loss: 0.485 | Val acc: 0.860\n",
            "\n",
            "Epoch: 137\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.490 | Val acc: 0.859\n",
            "\n",
            "Epoch: 138\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.502 | Val acc: 0.859\n",
            "\n",
            "Epoch: 139\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.514 | Val acc: 0.853\n",
            "\n",
            "Epoch: 140\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.514 | Val acc: 0.854\n",
            "\n",
            "Epoch: 141\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.502 | Val acc: 0.857\n",
            "\n",
            "Epoch: 142\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.501 | Val acc: 0.860\n",
            "\n",
            "Epoch: 143\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.496 | Val acc: 0.861\n",
            "\n",
            "Epoch: 144\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.083 | Train acc: 0.973\n",
            "Val loss: 0.521 | Val acc: 0.850\n",
            "\n",
            "Epoch: 145\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.503 | Val acc: 0.858\n",
            "\n",
            "Epoch: 146\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.490 | Val acc: 0.859\n",
            "\n",
            "Epoch: 147\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.505 | Val acc: 0.860\n",
            "\n",
            "Epoch: 148\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.495 | Val acc: 0.859\n",
            "\n",
            "Epoch: 149\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.506 | Val acc: 0.851\n",
            "\n",
            "Epoch: 150\n",
            "learning rate:  1.0000000000000003e-05\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.498 | Val acc: 0.860\n",
            "\n",
            "Epoch: 151\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.506 | Val acc: 0.857\n",
            "\n",
            "Epoch: 152\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.082 | Train acc: 0.974\n",
            "Val loss: 0.498 | Val acc: 0.862\n",
            "\n",
            "Epoch: 153\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.498 | Val acc: 0.859\n",
            "\n",
            "Epoch: 154\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.530 | Val acc: 0.854\n",
            "\n",
            "Epoch: 155\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.521 | Val acc: 0.851\n",
            "\n",
            "Epoch: 156\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.501 | Val acc: 0.859\n",
            "\n",
            "Epoch: 157\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.521 | Val acc: 0.858\n",
            "\n",
            "Epoch: 158\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.526 | Val acc: 0.857\n",
            "\n",
            "Epoch: 159\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.517 | Val acc: 0.859\n",
            "\n",
            "Epoch: 160\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.078 | Train acc: 0.973\n",
            "Val loss: 0.514 | Val acc: 0.857\n",
            "\n",
            "Epoch: 161\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.502 | Val acc: 0.854\n",
            "\n",
            "Epoch: 162\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.505 | Val acc: 0.863\n",
            "\n",
            "Epoch: 163\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.511 | Val acc: 0.857\n",
            "\n",
            "Epoch: 164\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.500 | Val acc: 0.854\n",
            "\n",
            "Epoch: 165\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.500 | Val acc: 0.856\n",
            "\n",
            "Epoch: 166\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.525 | Val acc: 0.855\n",
            "\n",
            "Epoch: 167\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.514 | Val acc: 0.857\n",
            "\n",
            "Epoch: 168\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.492 | Val acc: 0.859\n",
            "\n",
            "Epoch: 169\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.513 | Val acc: 0.854\n",
            "\n",
            "Epoch: 170\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.493 | Val acc: 0.861\n",
            "\n",
            "Epoch: 171\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.519 | Val acc: 0.854\n",
            "\n",
            "Epoch: 172\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.081 | Train acc: 0.974\n",
            "Val loss: 0.513 | Val acc: 0.857\n",
            "\n",
            "Epoch: 173\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.510 | Val acc: 0.855\n",
            "\n",
            "Epoch: 174\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.498 | Val acc: 0.856\n",
            "\n",
            "Epoch: 175\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.498 | Val acc: 0.860\n",
            "\n",
            "Epoch: 176\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.515 | Val acc: 0.855\n",
            "\n",
            "Epoch: 177\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.518 | Val acc: 0.856\n",
            "\n",
            "Epoch: 178\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.501 | Val acc: 0.860\n",
            "\n",
            "Epoch: 179\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.503 | Val acc: 0.857\n",
            "\n",
            "Epoch: 180\n",
            "learning rate:  1.0000000000000004e-06\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.496 | Val acc: 0.859\n",
            "\n",
            "Epoch: 181\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.508 | Val acc: 0.856\n",
            "\n",
            "Epoch: 182\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.080 | Train acc: 0.972\n",
            "Val loss: 0.529 | Val acc: 0.853\n",
            "\n",
            "Epoch: 183\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.503 | Val acc: 0.856\n",
            "\n",
            "Epoch: 184\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.520 | Val acc: 0.855\n",
            "\n",
            "Epoch: 185\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.509 | Val acc: 0.857\n",
            "\n",
            "Epoch: 186\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.533 | Val acc: 0.852\n",
            "\n",
            "Epoch: 187\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.503 | Val acc: 0.857\n",
            "\n",
            "Epoch: 188\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.083 | Train acc: 0.973\n",
            "Val loss: 0.487 | Val acc: 0.860\n",
            "\n",
            "Epoch: 189\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.481 | Val acc: 0.863\n",
            "\n",
            "Epoch: 190\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.078 | Train acc: 0.974\n",
            "Val loss: 0.504 | Val acc: 0.858\n",
            "\n",
            "Epoch: 191\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.473 | Val acc: 0.857\n",
            "\n",
            "Epoch: 192\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.521 | Val acc: 0.859\n",
            "\n",
            "Epoch: 193\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.498 | Val acc: 0.856\n",
            "\n",
            "Epoch: 194\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.505 | Val acc: 0.861\n",
            "\n",
            "Epoch: 195\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.478 | Val acc: 0.861\n",
            "\n",
            "Epoch: 196\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.534 | Val acc: 0.853\n",
            "\n",
            "Epoch: 197\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.516 | Val acc: 0.857\n",
            "\n",
            "Epoch: 198\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.503 | Val acc: 0.859\n",
            "\n",
            "Epoch: 199\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.510 | Val acc: 0.856\n",
            "\n",
            "Epoch: 200\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.517 | Val acc: 0.857\n",
            "\n",
            "Epoch: 201\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.529 | Val acc: 0.854\n",
            "\n",
            "Epoch: 202\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.528 | Val acc: 0.853\n",
            "\n",
            "Epoch: 203\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.524 | Val acc: 0.853\n",
            "\n",
            "Epoch: 204\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.494 | Val acc: 0.860\n",
            "\n",
            "Epoch: 205\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.511 | Val acc: 0.850\n",
            "\n",
            "Epoch: 206\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.502 | Val acc: 0.860\n",
            "\n",
            "Epoch: 207\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.489 | Val acc: 0.857\n",
            "\n",
            "Epoch: 208\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.518 | Val acc: 0.861\n",
            "\n",
            "Epoch: 209\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.504 | Val acc: 0.853\n",
            "\n",
            "Epoch: 210\n",
            "learning rate:  1.0000000000000005e-07\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.495 | Val acc: 0.853\n",
            "\n",
            "Epoch: 211\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.509 | Val acc: 0.857\n",
            "\n",
            "Epoch: 212\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.516 | Val acc: 0.856\n",
            "\n",
            "Epoch: 213\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.084 | Train acc: 0.973\n",
            "Val loss: 0.496 | Val acc: 0.860\n",
            "\n",
            "Epoch: 214\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.476 | Val acc: 0.864\n",
            "\n",
            "Epoch: 215\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.078 | Train acc: 0.974\n",
            "Val loss: 0.498 | Val acc: 0.856\n",
            "\n",
            "Epoch: 216\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.498 | Val acc: 0.863\n",
            "\n",
            "Epoch: 217\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.541 | Val acc: 0.851\n",
            "\n",
            "Epoch: 218\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.505 | Val acc: 0.858\n",
            "\n",
            "Epoch: 219\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.515 | Val acc: 0.858\n",
            "\n",
            "Epoch: 220\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.505 | Val acc: 0.855\n",
            "\n",
            "Epoch: 221\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.510 | Val acc: 0.860\n",
            "\n",
            "Epoch: 222\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.528 | Val acc: 0.855\n",
            "\n",
            "Epoch: 223\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.520 | Val acc: 0.854\n",
            "\n",
            "Epoch: 224\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.499 | Val acc: 0.863\n",
            "\n",
            "Epoch: 225\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.504 | Val acc: 0.861\n",
            "\n",
            "Epoch: 226\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.507 | Val acc: 0.858\n",
            "\n",
            "Epoch: 227\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.507 | Val acc: 0.856\n",
            "\n",
            "Epoch: 228\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.524 | Val acc: 0.856\n",
            "\n",
            "Epoch: 229\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.503 | Val acc: 0.859\n",
            "\n",
            "Epoch: 230\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.513 | Val acc: 0.852\n",
            "\n",
            "Epoch: 231\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.498 | Val acc: 0.853\n",
            "\n",
            "Epoch: 232\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.515 | Val acc: 0.855\n",
            "\n",
            "Epoch: 233\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.485 | Val acc: 0.857\n",
            "\n",
            "Epoch: 234\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.505 | Val acc: 0.861\n",
            "\n",
            "Epoch: 235\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.514 | Val acc: 0.858\n",
            "\n",
            "Epoch: 236\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.484 | Val acc: 0.861\n",
            "\n",
            "Epoch: 237\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.515 | Val acc: 0.852\n",
            "\n",
            "Epoch: 238\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.974\n",
            "Val loss: 0.495 | Val acc: 0.857\n",
            "\n",
            "Epoch: 239\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.527 | Val acc: 0.852\n",
            "\n",
            "Epoch: 240\n",
            "learning rate:  1.0000000000000004e-08\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.498 | Val acc: 0.860\n",
            "\n",
            "Epoch: 241\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.492 | Val acc: 0.859\n",
            "\n",
            "Epoch: 242\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.511 | Val acc: 0.858\n",
            "\n",
            "Epoch: 243\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.083 | Train acc: 0.971\n",
            "Val loss: 0.489 | Val acc: 0.862\n",
            "\n",
            "Epoch: 244\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.510 | Val acc: 0.852\n",
            "\n",
            "Epoch: 245\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.489 | Val acc: 0.865\n",
            "\n",
            "Epoch: 246\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.081 | Train acc: 0.974\n",
            "Val loss: 0.516 | Val acc: 0.855\n",
            "\n",
            "Epoch: 247\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.083 | Train acc: 0.973\n",
            "Val loss: 0.497 | Val acc: 0.858\n",
            "\n",
            "Epoch: 248\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.506 | Val acc: 0.856\n",
            "\n",
            "Epoch: 249\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.493 | Val acc: 0.858\n",
            "\n",
            "Epoch: 250\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.485 | Val acc: 0.860\n",
            "\n",
            "Epoch: 251\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.501 | Val acc: 0.859\n",
            "\n",
            "Epoch: 252\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.501 | Val acc: 0.855\n",
            "\n",
            "Epoch: 253\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.517 | Val acc: 0.857\n",
            "\n",
            "Epoch: 254\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.506 | Val acc: 0.855\n",
            "\n",
            "Epoch: 255\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.524 | Val acc: 0.852\n",
            "\n",
            "Epoch: 256\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.078 | Train acc: 0.974\n",
            "Val loss: 0.511 | Val acc: 0.853\n",
            "\n",
            "Epoch: 257\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.503 | Val acc: 0.860\n",
            "\n",
            "Epoch: 258\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.084 | Train acc: 0.972\n",
            "Val loss: 0.522 | Val acc: 0.853\n",
            "\n",
            "Epoch: 259\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.509 | Val acc: 0.859\n",
            "\n",
            "Epoch: 260\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.530 | Val acc: 0.849\n",
            "\n",
            "Epoch: 261\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.507 | Val acc: 0.857\n",
            "\n",
            "Epoch: 262\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.506 | Val acc: 0.857\n",
            "\n",
            "Epoch: 263\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.527 | Val acc: 0.850\n",
            "\n",
            "Epoch: 264\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.510 | Val acc: 0.858\n",
            "\n",
            "Epoch: 265\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.491 | Val acc: 0.859\n",
            "\n",
            "Epoch: 266\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.485 | Val acc: 0.863\n",
            "\n",
            "Epoch: 267\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.527 | Val acc: 0.855\n",
            "\n",
            "Epoch: 268\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.510 | Val acc: 0.853\n",
            "\n",
            "Epoch: 269\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.081 | Train acc: 0.974\n",
            "Val loss: 0.497 | Val acc: 0.863\n",
            "\n",
            "Epoch: 270\n",
            "learning rate:  1.0000000000000005e-09\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.507 | Val acc: 0.856\n",
            "\n",
            "Epoch: 271\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.501 | Val acc: 0.858\n",
            "\n",
            "Epoch: 272\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.514 | Val acc: 0.856\n",
            "\n",
            "Epoch: 273\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.503 | Val acc: 0.857\n",
            "\n",
            "Epoch: 274\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.504 | Val acc: 0.858\n",
            "\n",
            "Epoch: 275\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.511 | Val acc: 0.853\n",
            "\n",
            "Epoch: 276\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.085 | Train acc: 0.972\n",
            "Val loss: 0.510 | Val acc: 0.857\n",
            "\n",
            "Epoch: 277\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.081 | Train acc: 0.974\n",
            "Val loss: 0.514 | Val acc: 0.857\n",
            "\n",
            "Epoch: 278\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.503 | Val acc: 0.859\n",
            "\n",
            "Epoch: 279\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.081 | Train acc: 0.974\n",
            "Val loss: 0.504 | Val acc: 0.854\n",
            "\n",
            "Epoch: 280\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.485 | Val acc: 0.861\n",
            "\n",
            "Epoch: 281\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.083 | Train acc: 0.973\n",
            "Val loss: 0.504 | Val acc: 0.857\n",
            "\n",
            "Epoch: 282\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.502 | Val acc: 0.859\n",
            "\n",
            "Epoch: 283\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.505 | Val acc: 0.859\n",
            "\n",
            "Epoch: 284\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.500 | Val acc: 0.859\n",
            "\n",
            "Epoch: 285\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.078 | Train acc: 0.974\n",
            "Val loss: 0.511 | Val acc: 0.856\n",
            "\n",
            "Epoch: 286\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.513 | Val acc: 0.855\n",
            "\n",
            "Epoch: 287\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.501 | Val acc: 0.858\n",
            "\n",
            "Epoch: 288\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.494 | Val acc: 0.859\n",
            "\n",
            "Epoch: 289\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.500 | Val acc: 0.853\n",
            "\n",
            "Epoch: 290\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.511 | Val acc: 0.857\n",
            "\n",
            "Epoch: 291\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.511 | Val acc: 0.853\n",
            "\n",
            "Epoch: 292\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.517 | Val acc: 0.856\n",
            "\n",
            "Epoch: 293\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.498 | Val acc: 0.855\n",
            "\n",
            "Epoch: 294\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.513 | Val acc: 0.859\n",
            "\n",
            "Epoch: 295\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.077 | Train acc: 0.974\n",
            "Val loss: 0.496 | Val acc: 0.859\n",
            "\n",
            "Epoch: 296\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.509 | Val acc: 0.854\n",
            "\n",
            "Epoch: 297\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.514 | Val acc: 0.855\n",
            "\n",
            "Epoch: 298\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.510 | Val acc: 0.857\n",
            "\n",
            "Epoch: 299\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.497 | Val acc: 0.857\n",
            "\n",
            "Epoch: 300\n",
            "learning rate:  1.0000000000000006e-10\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.507 | Val acc: 0.859\n",
            "\n",
            "Epoch: 301\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.497 | Val acc: 0.857\n",
            "\n",
            "Epoch: 302\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.504 | Val acc: 0.860\n",
            "\n",
            "Epoch: 303\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.515 | Val acc: 0.853\n",
            "\n",
            "Epoch: 304\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.511 | Val acc: 0.859\n",
            "\n",
            "Epoch: 305\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.079 | Train acc: 0.974\n",
            "Val loss: 0.504 | Val acc: 0.854\n",
            "\n",
            "Epoch: 306\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.504 | Val acc: 0.860\n",
            "\n",
            "Epoch: 307\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.083 | Train acc: 0.972\n",
            "Val loss: 0.522 | Val acc: 0.857\n",
            "\n",
            "Epoch: 308\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.081 | Train acc: 0.974\n",
            "Val loss: 0.497 | Val acc: 0.857\n",
            "\n",
            "Epoch: 309\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.079 | Train acc: 0.973\n",
            "Val loss: 0.503 | Val acc: 0.856\n",
            "\n",
            "Epoch: 310\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.518 | Val acc: 0.854\n",
            "\n",
            "Epoch: 311\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.518 | Val acc: 0.857\n",
            "\n",
            "Epoch: 312\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.080 | Train acc: 0.973\n",
            "Val loss: 0.523 | Val acc: 0.859\n",
            "\n",
            "Epoch: 313\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.502 | Val acc: 0.859\n",
            "\n",
            "Epoch: 314\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.487 | Val acc: 0.860\n",
            "\n",
            "Epoch: 315\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.080 | Train acc: 0.974\n",
            "Val loss: 0.526 | Val acc: 0.855\n",
            "\n",
            "Epoch: 316\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.081 | Train acc: 0.973\n",
            "Val loss: 0.496 | Val acc: 0.854\n",
            "\n",
            "Epoch: 317\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.081 | Train acc: 0.972\n",
            "Val loss: 0.516 | Val acc: 0.863\n",
            "\n",
            "Epoch: 318\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.078 | Train acc: 0.974\n",
            "Val loss: 0.499 | Val acc: 0.859\n",
            "\n",
            "Epoch: 319\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.082 | Train acc: 0.973\n",
            "Val loss: 0.508 | Val acc: 0.853\n",
            "\n",
            "Epoch: 320\n",
            "learning rate:  1.0000000000000006e-11\n",
            "Train loss: 0.082 | Train acc: 0.972\n",
            "Val loss: 0.490 | Val acc: 0.860\n",
            "Test loss: 0.505 | Test acc: 0.863\n"
          ]
        }
      ],
      "source": [
        "#是否pretrain\n",
        "print(torch.cuda.device_count())    #Weichuan\n",
        "print(torch.cuda.is_available())    #Weichuan\n",
        "net = models.resnet18(pretrained = False).to(device)\n",
        "\n",
        "# 定義損失函數和優化方式\n",
        "criterion = nn.CrossEntropyLoss()  #loss function \n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)   # momentum-SGD，採用L2正則化（權重衰減）\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones=[5,10,15,20,25,30,35],gamma=0.1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_loss, train_acc = [], []\n",
        "    val_loss, val_acc = [], []\n",
        "    for epoch in range(EPOCH):\n",
        "        # train\n",
        "        net.train()\n",
        "        sum1_loss, sum2_loss = 0.0, 0.0\n",
        "        correct = 0.0\n",
        "        total = 0.0\n",
        "        print('\\nEpoch: %d' % (epoch + 1))\n",
        "        for i, traindata in enumerate(trainloader, 0):\n",
        "            # prepare data\n",
        "            inputs, train_labels = traindata\n",
        "            inputs, train_labels = inputs.to(device), train_labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward\n",
        "            train_outputs = net(inputs)\n",
        "            trainloss = criterion(train_outputs, train_labels)\n",
        "            trainloss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 每訓練1個batch的loss和acc\n",
        "            sum1_loss += trainloss.item()\n",
        "            _, predicted = torch.max(train_outputs.data, 1)     # 取得分數最高的那個類 (outputs.data的index)\n",
        "            total += train_labels.size(0)\n",
        "            correct += predicted.eq(train_labels.data).cpu().sum()\n",
        "\n",
        "        # learning rate schedule\n",
        "        writer.add_scalar(\"lr\", optimizer.param_groups[0]['lr'], epoch)\n",
        "        adjust_learning_rate(optimizer, epoch, lr)\n",
        "        print(\"learning rate: \",  optimizer.param_groups[0]['lr'])\n",
        "        \n",
        "        loss1 = sum1_loss / (i + 1)\n",
        "        acc1 = correct / total\n",
        "        print(\"Train loss: %.3f | Train acc: %.3f\" % (loss1, acc1))\n",
        "        train_loss.append(loss1)\n",
        "        train_acc.append(acc1.item())\n",
        "\n",
        "        # 用val驗證\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for j, valdata in enumerate(valloader, 0):\n",
        "                net.eval()\n",
        "                images, val_labels = valdata\n",
        "                images, val_labels = images.to(device), val_labels.to(device)\n",
        "                val_outputs = net(images)\n",
        "                valloss = criterion(val_outputs, val_labels)\n",
        "                        \n",
        "                sum2_loss += valloss.item()\n",
        "                _, predicted = torch.max(val_outputs.data, 1)\n",
        "                total += val_labels.size(0)\n",
        "                correct += (predicted == val_labels).sum()\n",
        "                    \n",
        "            loss2 = sum2_loss / (j + 1)\n",
        "            acc2 = correct / total\n",
        "            print(\"Val loss: %.3f | Val acc: %.3f\" % (loss2, acc2))\n",
        "            val_loss.append(loss2)\n",
        "            val_acc.append(acc2.item())\n",
        "\n",
        "    # 用test測試\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        sum3_loss = 0.0\n",
        "        for k, testdata in enumerate(testloader, 0):\n",
        "            net.eval()\n",
        "            imgs, test_labels = testdata\n",
        "            imgs, test_labels = imgs.to(device), test_labels.to(device)\n",
        "            test_outputs = net(imgs)\n",
        "            testloss = criterion(test_outputs, test_labels)\n",
        "                        \n",
        "            sum3_loss += testloss.item()\n",
        "            _, predicted = torch.max(test_outputs.data, 1)\n",
        "            total += test_labels.size(0)\n",
        "            correct += (predicted == test_labels).sum()\n",
        "                    \n",
        "        loss3 = sum3_loss / (k + 1)\n",
        "        acc3 = correct / total\n",
        "        print(\"Test loss: %.3f | Test acc: %.3f\" % (loss3, acc3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "g-QShVIgmicX",
        "outputId": "abef98df-a7ef-4a16-f3e5-f8508c1ea691"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot accuracy curve\n",
        "plt.figure(0)\n",
        "plt.plot(range(1,EPOCH+1,1), np.array(train_acc), 'r-', label= \"train accuracy\") \n",
        "plt.plot(range(1,EPOCH+1,1), np.array(val_acc), 'b-', label= \"val accuracy\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot loss curve\n",
        "plt.figure(1)\n",
        "plt.plot(range(1,EPOCH+1,1), np.array(train_loss), 'r-', label= \"train loss\") \n",
        "plt.plot(range(1,EPOCH+1,1), np.array(val_loss), 'b-', label= \"val loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0dddca853b346029d59165177eb7a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ba6819814e141eb8334c854c2fbddd0",
              "IPY_MODEL_eae82692647a460bb72cdc819db30e48",
              "IPY_MODEL_43b4f6866bb04b4b861e1f7d8770c921"
            ],
            "layout": "IPY_MODEL_e2f941f618d7456899f7aa914a51a367"
          }
        },
        "7ba6819814e141eb8334c854c2fbddd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb647ed2322441e6b5ed076023a79347",
            "placeholder": "​",
            "style": "IPY_MODEL_3ce7c157195c4406b23ea5443e966130",
            "value": "100%"
          }
        },
        "eae82692647a460bb72cdc819db30e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47051a50b5e94bc4be684908e9de6e8f",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dcee7bc4b0245e19cc7b3b9922d7523",
            "value": 170498071
          }
        },
        "43b4f6866bb04b4b861e1f7d8770c921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef5c4d4ee24b4afb96da843e5326b695",
            "placeholder": "​",
            "style": "IPY_MODEL_7cd57a831e9c4ae586263b21a9942a61",
            "value": " 170498071/170498071 [00:02&lt;00:00, 71716524.64it/s]"
          }
        },
        "e2f941f618d7456899f7aa914a51a367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb647ed2322441e6b5ed076023a79347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce7c157195c4406b23ea5443e966130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47051a50b5e94bc4be684908e9de6e8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dcee7bc4b0245e19cc7b3b9922d7523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef5c4d4ee24b4afb96da843e5326b695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd57a831e9c4ae586263b21a9942a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}